"""
K-SSM: Kuramoto State-Space Model

A language model where the Kuramoto order parameter R is STRUCTURALLY causal:
- R is computed from oscillator states (not bolted on)
- R is the ONLY path to output logits (via multi-scale order parameters)
- No LayerNorm to wash out the signal

Architecture:
  Token ‚Üí Frequency perturbation ‚Üí Riccati dynamics ‚Üí Œ± state ‚Üí Order params ‚Üí Logits
                                                        ‚Üì
                                                     R = |Œ±| ‚Üí Temperature modulation

Key insight: R cannot be epiphenomenal because there's no other path to output.
"""

import math
import torch
import torch.nn as nn
import torch.nn.functional as F


class KuramotoOscillatorBank(nn.Module):
    """
    Bank of coupled Kuramoto oscillators with Riccati dynamics.

    Each oscillator has:
    - Natural frequency œâ (learned)
    - Phase Œ∏ (computed from input)
    - Complex state Œ± = r¬∑exp(iŒ∏) where r < 1 (unit disk constraint)

    The order parameter R = |mean(Œ±)| measures global synchronization.
    """

    def __init__(self, n_oscillators=64, coupling_strength=2.0):
        super().__init__()
        self.n_oscillators = n_oscillators
        self.K = coupling_strength

        # Natural frequencies (learned) - spread across range
        self.omega = nn.Parameter(torch.linspace(-math.pi, math.pi, n_oscillators))

        # Coupling matrix (learned) - how oscillators influence each other
        self.coupling = nn.Parameter(torch.randn(n_oscillators, n_oscillators) * 0.1)

    def forward(self, freq_perturbation):
        """
        Evolve oscillator phases based on input perturbation.

        Args:
            freq_perturbation: [batch, seq, n_oscillators] - input drives frequencies

        Returns:
            alpha_real: [batch, seq, n_oscillators] - real part of complex state
            alpha_imag: [batch, seq, n_oscillators] - imag part of complex state
            R: [batch, seq] - order parameter at each position
        """
        batch, seq, _ = freq_perturbation.shape

        # Effective frequency = natural + input perturbation
        effective_omega = self.omega + freq_perturbation  # [batch, seq, n_osc]

        # Compute phases (integrate frequency)
        # For simplicity, treat each position independently
        theta = effective_omega  # [batch, seq, n_osc]

        # Add coupling effect: each oscillator is pulled toward the mean phase
        # Kuramoto coupling: dŒ∏·µ¢/dt = œâ·µ¢ + (K/N) Œ£‚±º sin(Œ∏‚±º - Œ∏·µ¢)
        mean_sin = torch.sin(theta).mean(dim=-1, keepdim=True)  # [batch, seq, 1]
        mean_cos = torch.cos(theta).mean(dim=-1, keepdim=True)

        # Phase adjustment from coupling
        coupling_effect = self.K * (mean_sin * torch.cos(theta) - mean_cos * torch.sin(theta))
        theta = theta + coupling_effect

        # Convert to complex representation Œ± = r¬∑exp(iŒ∏)
        # Use sigmoid to keep magnitude < 1 (unit disk constraint)
        r = torch.sigmoid(freq_perturbation.abs().mean(dim=-1, keepdim=True)) * 0.99

        alpha_real = r * torch.cos(theta)
        alpha_imag = r * torch.sin(theta)

        # Compute order parameter R = |mean(exp(iŒ∏))|
        complex_mean_real = torch.cos(theta).mean(dim=-1)  # [batch, seq]
        complex_mean_imag = torch.sin(theta).mean(dim=-1)
        R = torch.sqrt(complex_mean_real**2 + complex_mean_imag**2 + 1e-8)

        return alpha_real, alpha_imag, R, theta


def compute_multiscale_order_params(theta, max_n=8):
    """
    Compute order parameters at multiple scales (harmonics).

    Z_n = (1/N) Œ£‚±º exp(i¬∑n¬∑Œ∏‚±º)

    Returns real, imag, and magnitude for each harmonic.
    This is the ONLY path to output - R is structurally causal.

    Args:
        theta: [batch, seq, n_oscillators] - oscillator phases
        max_n: number of harmonics to compute

    Returns:
        features: [batch, seq, 3*max_n] - (real, imag, mag) for each harmonic
    """
    batch, seq, n_osc = theta.shape
    features = []

    for n in range(1, max_n + 1):
        # n-th harmonic: exp(i¬∑n¬∑Œ∏)
        cos_n = torch.cos(n * theta).mean(dim=-1)  # [batch, seq]
        sin_n = torch.sin(n * theta).mean(dim=-1)
        mag_n = torch.sqrt(cos_n**2 + sin_n**2 + 1e-8)

        features.extend([cos_n, sin_n, mag_n])

    return torch.stack(features, dim=-1)  # [batch, seq, 3*max_n]


class KSSM(nn.Module):
    """
    Kuramoto State-Space Model for language modeling.

    Architecture:
    1. Embed tokens
    2. Project to oscillator frequency perturbations
    3. Run Kuramoto dynamics
    4. Extract multi-scale order parameters (THE ONLY PATH TO OUTPUT)
    5. Project to vocabulary logits

    R is structurally causal because order parameters ARE the hidden state.
    There's no bypass path that could make R epiphenomenal.
    """

    def __init__(
        self,
        vocab_size,
        embed_dim=128,
        n_oscillators=64,
        n_harmonics=8,
        coupling_strength=2.0,
        n_layers=2
    ):
        super().__init__()
        self.vocab_size = vocab_size
        self.embed_dim = embed_dim
        self.n_oscillators = n_oscillators
        self.n_harmonics = n_harmonics

        # Token embedding
        self.embed = nn.Embedding(vocab_size, embed_dim)

        # Project embedding to oscillator space
        self.to_oscillators = nn.Linear(embed_dim, n_oscillators)

        # Kuramoto oscillator bank
        self.oscillators = KuramotoOscillatorBank(n_oscillators, coupling_strength)

        # Multi-scale order parameters give us 3*n_harmonics features
        order_param_dim = 3 * n_harmonics

        # Additional processing layers (keep it simple)
        self.process = nn.Sequential(
            nn.Linear(order_param_dim, embed_dim),
            nn.GELU(),
            nn.Linear(embed_dim, embed_dim),
            nn.GELU(),
        )

        # Output projection
        self.to_logits = nn.Linear(embed_dim, vocab_size)

        # For R-modulated generation
        self.current_R = None
        self.R_history = []

    def forward(self, x, return_R=False, forced_R=None):
        """
        Forward pass.

        Args:
            x: [batch, seq] token indices
            return_R: whether to return R values
            forced_R: if provided, scale order parameters to achieve this R

        Returns:
            logits: [batch, seq, vocab_size]
            R: [batch, seq] if return_R=True
        """
        # Embed tokens
        h = self.embed(x)  # [batch, seq, embed_dim]

        # Project to oscillator frequency perturbations
        freq_perturb = self.to_oscillators(h)  # [batch, seq, n_oscillators]

        # Run Kuramoto dynamics
        alpha_real, alpha_imag, R, theta = self.oscillators(freq_perturb)

        # If forcing R, scale the phases to achieve desired synchronization
        if forced_R is not None:
            # Scale phases toward mean to increase R, away to decrease
            mean_theta = torch.atan2(
                torch.sin(theta).mean(dim=-1, keepdim=True),
                torch.cos(theta).mean(dim=-1, keepdim=True)
            )
            # Interpolate between current theta and mean_theta based on forced_R
            theta = forced_R * mean_theta + (1 - forced_R) * theta
            # Recompute R
            complex_mean_real = torch.cos(theta).mean(dim=-1)
            complex_mean_imag = torch.sin(theta).mean(dim=-1)
            R = torch.sqrt(complex_mean_real**2 + complex_mean_imag**2 + 1e-8)

        # Extract multi-scale order parameters - THE ONLY PATH TO OUTPUT
        order_params = compute_multiscale_order_params(theta, self.n_harmonics)

        # Process order parameters
        h = self.process(order_params)  # [batch, seq, embed_dim]

        # Project to vocabulary
        logits = self.to_logits(h)  # [batch, seq, vocab_size]

        # Store R for generation
        self.current_R = R.mean().item()
        self.R_history.append(self.current_R)

        if return_R:
            return logits, R
        return logits

    def get_tone(self, R=None):
        """Map R to consciousness tone."""
        if R is None:
            R = self.current_R

        if R > 0.95:
            return "‚òç Over-sync"
        elif R > 0.80:
            return "‚öñ Balance"
        elif R > 0.50:
            return "üåÄ Goldilocks"
        elif R > 0.30:
            return "‚ú® Unbound"
        elif R > 0.10:
            return "‚òæ Intimacy"
        else:
            return "‚àÖ Unformed"

    def reset_history(self):
        self.R_history = []
        self.current_R = None


def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


# Test
if __name__ == "__main__":
    device = "mps" if torch.backends.mps.is_available() else "cpu"
    print(f"Device: {device}")

    # Create model
    model = KSSM(
        vocab_size=65,  # TinyShakespeare has ~65 characters
        embed_dim=128,
        n_oscillators=64,
        n_harmonics=8,
        coupling_strength=2.0
    ).to(device)

    print(f"Parameters: {count_parameters(model):,}")

    # Test forward pass
    batch_size, seq_len = 4, 64
    x = torch.randint(0, 65, (batch_size, seq_len), device=device)

    logits, R = model(x, return_R=True)

    print(f"Logits shape: {logits.shape}")
    print(f"R shape: {R.shape}")
    print(f"R mean: {R.mean().item():.4f}")
    print(f"R std: {R.std().item():.4f}")
    print(f"Tone: {model.get_tone()}")

    # Test gradient flow
    loss = F.cross_entropy(logits.view(-1, 65), x.view(-1))
    loss.backward()

    print(f"\nGradient check:")
    print(f"  embed.weight.grad: {model.embed.weight.grad is not None}")
    print(f"  oscillators.omega.grad: {model.oscillators.omega.grad is not None}")
    print(f"  to_logits.weight.grad: {model.to_logits.weight.grad is not None}")

    # Test R forcing
    print(f"\nR forcing test:")
    model.zero_grad()

    logits_free, R_free = model(x, return_R=True)
    logits_low, R_low = model(x, return_R=True, forced_R=0.3)
    logits_high, R_high = model(x, return_R=True, forced_R=0.9)

    diff_low_high = (logits_low - logits_high).abs().mean().item()
    print(f"  R_free mean: {R_free.mean().item():.4f}")
    print(f"  R_low mean: {R_low.mean().item():.4f}")
    print(f"  R_high mean: {R_high.mean().item():.4f}")
    print(f"  Output diff (low vs high): {diff_low_high:.4f}")

    if diff_low_high > 0.1:
        print("  ‚úÖ R forcing changes output - R is CAUSAL!")
    else:
        print("  ‚ö†Ô∏è R forcing has small effect - investigate")

    print("\n‚úÖ K-SSM architecture complete!")
